{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuHSPwoO4H4/yP5qvwq7wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y-patankar/Bookstore_Application/blob/main/CreditCard_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WbB4mmJ8Rcz",
        "outputId": "70fc5242-b8bc-4c1c-dde8-0f65cfa8ab96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading creditcardfraud.zip to /content\n",
            " 94% 62.0M/66.0M [00:00<00:00, 123MB/s]\n",
            "100% 66.0M/66.0M [00:00<00:00, 111MB/s]\n",
            "Archive:  creditcardfraud.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mlg-ulb/creditcardfraud\n",
        "!unzip creditcardfraud.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas  as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "df= pd.read_csv('creditcard.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "Vzx_0IAE84IL",
        "outputId": "8f7e8e0d-1e53-46ff-a02e-abf18fd6a654"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
              "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
              "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
              "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
              "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
              "...          ...        ...        ...       ...       ...       ...   \n",
              "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
              "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
              "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
              "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
              "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
              "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
              "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
              "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
              "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
              "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
              "...          ...       ...       ...       ...       ...       ...     ...   \n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
              "\n",
              "        Class  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cc4d8cd-ae13-444d-83bd-5252aab965a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cc4d8cd-ae13-444d-83bd-5252aab965a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4cc4d8cd-ae13-444d-83bd-5252aab965a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4cc4d8cd-ae13-444d-83bd-5252aab965a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-adeb31db-66df-403f-a4ca-1b5c37a563c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-adeb31db-66df-403f-a4ca-1b5c37a563c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-adeb31db-66df-403f-a4ca-1b5c37a563c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9121e3cc-2a99-4ed3-b460-4630d89d36b7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9121e3cc-2a99-4ed3-b460-4630d89d36b7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the \"Time\" and \"Amount\" column"
      ],
      "metadata": {
        "id": "K2etAQwqyMvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "new_df = df.copy()\n",
        "new_df['Amount'] = RobustScaler().fit_transform(new_df['Amount'].to_numpy().reshape(-1, 1))\n",
        "time = new_df['Time']\n",
        "new_df['Time'] = (time - time.min()) / (time.max() - time.min())\n",
        "new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "1OAoX4FxUtv3",
        "outputId": "678203b2-0666-4916-f19b-9370fb76a43f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "0       0.000000  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
              "1       0.000000   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
              "2       0.000006  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
              "3       0.000006  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
              "4       0.000012  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
              "...          ...        ...        ...       ...       ...       ...   \n",
              "284802  0.999965 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  0.999971  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  0.999977   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  0.999977  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  1.000000  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
              "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
              "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
              "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
              "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
              "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  1.783274   \n",
              "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.269825   \n",
              "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  4.983721   \n",
              "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  1.418291   \n",
              "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  0.670579   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.296653   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  0.038986   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561  0.641096   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.167680   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  2.724796   \n",
              "\n",
              "        Class  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9e6c835-b430-4718-85f6-c71eb66e62f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>1.783274</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>-0.269825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>4.983721</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>1.418291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0.670579</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>0.999965</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>-0.296653</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>0.999971</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>0.038986</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>0.999977</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>0.641096</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>0.999977</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>-0.167680</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>2.724796</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9e6c835-b430-4718-85f6-c71eb66e62f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9e6c835-b430-4718-85f6-c71eb66e62f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9e6c835-b430-4718-85f6-c71eb66e62f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-44f617ff-e164-4423-a0a6-8428c42c7621\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44f617ff-e164-4423-a0a6-8428c42c7621')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-44f617ff-e164-4423-a0a6-8428c42c7621 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d42b646b-4cde-40b3-b531-c71939aa8dd5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('new_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d42b646b-4cde-40b3-b531-c71939aa8dd5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('new_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffeling the rows\n",
        "new_df = new_df.sample(frac=1, random_state=1)\n",
        "new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "NnzprzEH9k0x",
        "outputId": "0635c5de-b1b0-4341-a893-192311d932f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "169876  0.693938 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
              "127467  0.453377 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
              "137900  0.476770 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
              "21513   0.183556 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
              "134700  0.468326  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "21440   0.183261 -2.986845 -8.663978 -1.910863  0.664058 -3.934875  0.861269   \n",
              "117583  0.432480  0.937083 -0.849673  0.524186 -0.020031 -0.606327  0.692302   \n",
              "73349   0.318852 -1.149963  1.696462  1.637114  2.658991 -0.021502  0.192287   \n",
              "267336  0.941757  1.754554 -0.699398 -0.076332  0.443915 -0.672082  0.389061   \n",
              "128037  0.454743 -0.707635  0.493302  2.648089  1.064807 -0.680271  1.183838   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "169876  0.292491 -0.523020  0.358468  ... -0.075208  0.045536  0.380739   \n",
              "127467  0.321552  0.435975 -0.704298  ... -0.128619 -0.368565  0.090660   \n",
              "137900  0.706252 -0.064966 -0.463271  ... -0.305402 -0.774704 -0.123884   \n",
              "21513   0.681867 -0.031641  0.383872  ... -0.220815 -0.419013 -0.239197   \n",
              "134700  0.373692 -0.287204 -0.084482  ... -0.160161 -0.430404 -0.076738   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "21440   1.647511 -0.480963 -1.546866  ...  1.252092 -0.993085 -2.173147   \n",
              "117583 -0.463724  0.148857  0.785062  ... -0.143322 -0.479981 -0.237902   \n",
              "73349   0.205204  0.588754 -1.187820  ...  0.025147  0.086506 -0.262748   \n",
              "267336 -0.807534  0.202915  0.858635  ...  0.141950  0.358412  0.259748   \n",
              "128037  0.169413  0.074553  1.247988  ... -0.102350  0.323975 -0.172601   \n",
              "\n",
              "             V24       V25       V26       V27       V28     Amount  Class  \n",
              "169876  0.023440 -2.220686 -0.201146  0.066501  0.221180  -0.282401      0  \n",
              "127467  0.401147 -0.261034  0.080621  0.162427  0.059456  -0.279746      0  \n",
              "137900 -0.495687 -0.018148  0.121679  0.249050  0.092516  -0.294977      0  \n",
              "21513   0.009967  0.232829  0.814177  0.098797 -0.004273  -0.084119      0  \n",
              "134700  0.258708  0.552170  0.370701 -0.034255  0.041709  -0.296793      0  \n",
              "...          ...       ...       ...       ...       ...        ...    ...  \n",
              "21440   0.145570 -0.235062 -0.227411 -0.382702  0.404045  32.002515      0  \n",
              "117583 -0.715247  0.251418  0.975406 -0.060168  0.023771   2.086495      0  \n",
              "73349   0.321538  0.341667  0.210343 -0.162047  0.031193  -0.201495      0  \n",
              "267336  0.746839 -0.560808  0.104636 -0.005853 -0.019622   1.017257      0  \n",
              "128037  0.126965 -0.001998 -0.398741 -0.385589 -0.205589   0.500245      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cabc0b2-530f-4505-af58-e75b063129a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169876</th>\n",
              "      <td>0.693938</td>\n",
              "      <td>-0.611712</td>\n",
              "      <td>-0.769705</td>\n",
              "      <td>-0.149759</td>\n",
              "      <td>-0.224877</td>\n",
              "      <td>2.028577</td>\n",
              "      <td>-2.019887</td>\n",
              "      <td>0.292491</td>\n",
              "      <td>-0.523020</td>\n",
              "      <td>0.358468</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.075208</td>\n",
              "      <td>0.045536</td>\n",
              "      <td>0.380739</td>\n",
              "      <td>0.023440</td>\n",
              "      <td>-2.220686</td>\n",
              "      <td>-0.201146</td>\n",
              "      <td>0.066501</td>\n",
              "      <td>0.221180</td>\n",
              "      <td>-0.282401</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127467</th>\n",
              "      <td>0.453377</td>\n",
              "      <td>-0.814682</td>\n",
              "      <td>1.319219</td>\n",
              "      <td>1.329415</td>\n",
              "      <td>0.027273</td>\n",
              "      <td>-0.284871</td>\n",
              "      <td>-0.653985</td>\n",
              "      <td>0.321552</td>\n",
              "      <td>0.435975</td>\n",
              "      <td>-0.704298</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.128619</td>\n",
              "      <td>-0.368565</td>\n",
              "      <td>0.090660</td>\n",
              "      <td>0.401147</td>\n",
              "      <td>-0.261034</td>\n",
              "      <td>0.080621</td>\n",
              "      <td>0.162427</td>\n",
              "      <td>0.059456</td>\n",
              "      <td>-0.279746</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137900</th>\n",
              "      <td>0.476770</td>\n",
              "      <td>-0.318193</td>\n",
              "      <td>1.118618</td>\n",
              "      <td>0.969864</td>\n",
              "      <td>-0.127052</td>\n",
              "      <td>0.569563</td>\n",
              "      <td>-0.532484</td>\n",
              "      <td>0.706252</td>\n",
              "      <td>-0.064966</td>\n",
              "      <td>-0.463271</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.305402</td>\n",
              "      <td>-0.774704</td>\n",
              "      <td>-0.123884</td>\n",
              "      <td>-0.495687</td>\n",
              "      <td>-0.018148</td>\n",
              "      <td>0.121679</td>\n",
              "      <td>0.249050</td>\n",
              "      <td>0.092516</td>\n",
              "      <td>-0.294977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21513</th>\n",
              "      <td>0.183556</td>\n",
              "      <td>-1.328271</td>\n",
              "      <td>1.018378</td>\n",
              "      <td>1.775426</td>\n",
              "      <td>-1.574193</td>\n",
              "      <td>-0.117696</td>\n",
              "      <td>-0.457733</td>\n",
              "      <td>0.681867</td>\n",
              "      <td>-0.031641</td>\n",
              "      <td>0.383872</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.220815</td>\n",
              "      <td>-0.419013</td>\n",
              "      <td>-0.239197</td>\n",
              "      <td>0.009967</td>\n",
              "      <td>0.232829</td>\n",
              "      <td>0.814177</td>\n",
              "      <td>0.098797</td>\n",
              "      <td>-0.004273</td>\n",
              "      <td>-0.084119</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134700</th>\n",
              "      <td>0.468326</td>\n",
              "      <td>1.276712</td>\n",
              "      <td>0.617120</td>\n",
              "      <td>-0.578014</td>\n",
              "      <td>0.879173</td>\n",
              "      <td>0.061706</td>\n",
              "      <td>-1.472002</td>\n",
              "      <td>0.373692</td>\n",
              "      <td>-0.287204</td>\n",
              "      <td>-0.084482</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.160161</td>\n",
              "      <td>-0.430404</td>\n",
              "      <td>-0.076738</td>\n",
              "      <td>0.258708</td>\n",
              "      <td>0.552170</td>\n",
              "      <td>0.370701</td>\n",
              "      <td>-0.034255</td>\n",
              "      <td>0.041709</td>\n",
              "      <td>-0.296793</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21440</th>\n",
              "      <td>0.183261</td>\n",
              "      <td>-2.986845</td>\n",
              "      <td>-8.663978</td>\n",
              "      <td>-1.910863</td>\n",
              "      <td>0.664058</td>\n",
              "      <td>-3.934875</td>\n",
              "      <td>0.861269</td>\n",
              "      <td>1.647511</td>\n",
              "      <td>-0.480963</td>\n",
              "      <td>-1.546866</td>\n",
              "      <td>...</td>\n",
              "      <td>1.252092</td>\n",
              "      <td>-0.993085</td>\n",
              "      <td>-2.173147</td>\n",
              "      <td>0.145570</td>\n",
              "      <td>-0.235062</td>\n",
              "      <td>-0.227411</td>\n",
              "      <td>-0.382702</td>\n",
              "      <td>0.404045</td>\n",
              "      <td>32.002515</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117583</th>\n",
              "      <td>0.432480</td>\n",
              "      <td>0.937083</td>\n",
              "      <td>-0.849673</td>\n",
              "      <td>0.524186</td>\n",
              "      <td>-0.020031</td>\n",
              "      <td>-0.606327</td>\n",
              "      <td>0.692302</td>\n",
              "      <td>-0.463724</td>\n",
              "      <td>0.148857</td>\n",
              "      <td>0.785062</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.143322</td>\n",
              "      <td>-0.479981</td>\n",
              "      <td>-0.237902</td>\n",
              "      <td>-0.715247</td>\n",
              "      <td>0.251418</td>\n",
              "      <td>0.975406</td>\n",
              "      <td>-0.060168</td>\n",
              "      <td>0.023771</td>\n",
              "      <td>2.086495</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73349</th>\n",
              "      <td>0.318852</td>\n",
              "      <td>-1.149963</td>\n",
              "      <td>1.696462</td>\n",
              "      <td>1.637114</td>\n",
              "      <td>2.658991</td>\n",
              "      <td>-0.021502</td>\n",
              "      <td>0.192287</td>\n",
              "      <td>0.205204</td>\n",
              "      <td>0.588754</td>\n",
              "      <td>-1.187820</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025147</td>\n",
              "      <td>0.086506</td>\n",
              "      <td>-0.262748</td>\n",
              "      <td>0.321538</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>0.210343</td>\n",
              "      <td>-0.162047</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>-0.201495</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267336</th>\n",
              "      <td>0.941757</td>\n",
              "      <td>1.754554</td>\n",
              "      <td>-0.699398</td>\n",
              "      <td>-0.076332</td>\n",
              "      <td>0.443915</td>\n",
              "      <td>-0.672082</td>\n",
              "      <td>0.389061</td>\n",
              "      <td>-0.807534</td>\n",
              "      <td>0.202915</td>\n",
              "      <td>0.858635</td>\n",
              "      <td>...</td>\n",
              "      <td>0.141950</td>\n",
              "      <td>0.358412</td>\n",
              "      <td>0.259748</td>\n",
              "      <td>0.746839</td>\n",
              "      <td>-0.560808</td>\n",
              "      <td>0.104636</td>\n",
              "      <td>-0.005853</td>\n",
              "      <td>-0.019622</td>\n",
              "      <td>1.017257</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128037</th>\n",
              "      <td>0.454743</td>\n",
              "      <td>-0.707635</td>\n",
              "      <td>0.493302</td>\n",
              "      <td>2.648089</td>\n",
              "      <td>1.064807</td>\n",
              "      <td>-0.680271</td>\n",
              "      <td>1.183838</td>\n",
              "      <td>0.169413</td>\n",
              "      <td>0.074553</td>\n",
              "      <td>1.247988</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.102350</td>\n",
              "      <td>0.323975</td>\n",
              "      <td>-0.172601</td>\n",
              "      <td>0.126965</td>\n",
              "      <td>-0.001998</td>\n",
              "      <td>-0.398741</td>\n",
              "      <td>-0.385589</td>\n",
              "      <td>-0.205589</td>\n",
              "      <td>0.500245</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cabc0b2-530f-4505-af58-e75b063129a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cabc0b2-530f-4505-af58-e75b063129a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cabc0b2-530f-4505-af58-e75b063129a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f95be7fe-7aaf-4583-b137-fe14aa8c257f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f95be7fe-7aaf-4583-b137-fe14aa8c257f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f95be7fe-7aaf-4583-b137-fe14aa8c257f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5e31cad6-154c-4a2b-ba86-470dabfcda70\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('new_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5e31cad6-154c-4a2b-ba86-470dabfcda70 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('new_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the train, test and validation class\n",
        "train, test, val = new_df[:240000], new_df[240000:262000], new_df[262000:]\n",
        "train['Class'].value_counts(), test['Class'].value_counts(), val['Class'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3DgjuEY_Jex",
        "outputId": "1011b0dd-d72b-4e73-b158-387ed97f7624"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Class\n",
              " 0    239589\n",
              " 1       411\n",
              " Name: count, dtype: int64,\n",
              " Class\n",
              " 0    21955\n",
              " 1       45\n",
              " Name: count, dtype: int64,\n",
              " Class\n",
              " 0    22771\n",
              " 1       36\n",
              " Name: count, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#panda dataframe to numpy df\n",
        "train_np, test_np, val_np = train.to_numpy(), test.to_numpy(), val.to_numpy()\n",
        "train_np.shape, test_np.shape, val_np.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-ZQQq6WET2S",
        "outputId": "4f822dd6-271e-4a7f-9657-345193885f91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240000, 31), (22000, 31), (22807, 31))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the shapes of the datasets\n",
        "dataset_shapes = {\n",
        "    'Dataset': ['Training', 'Testing', 'Validation'],\n",
        "    'Number of Samples': [train_np.shape[0], test_np.shape[0], val_np.shape[0]],\n",
        "    'Number of Features': [train_np.shape[1], test_np.shape[1], val_np.shape[1]]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df_shapes = pd.DataFrame(dataset_shapes)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df_shapes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpJma9KTqp99",
        "outputId": "ac6bcb25-9042-4fa5-c789-dc8bffe41bdf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Dataset  Number of Samples  Number of Features\n",
            "0    Training             240000                  31\n",
            "1     Testing              22000                  31\n",
            "2  Validation              22807                  31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seperating the features and labels\n",
        "x_train, y_train = train_np[:, :-1], train_np[:, -1]\n",
        "x_test, y_test = test_np[:, :-1], test_np[:, -1]\n",
        "x_val, y_val = val_np[:, :-1], val_np[:, -1]\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fboKpwTUuzF",
        "outputId": "06d21186-77eb-4063-efe8-709164e7f0e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240000, 30), (240000,), (22000, 30), (22000,), (22807, 30), (22807,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning the model with unbalanced dataset."
      ],
      "metadata": {
        "id": "LaGtDBOvzAvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression object\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# train the model on train set\n",
        "lr.fit(x_train, y_train.ravel())\n",
        "\n",
        "predictions = lr.predict(x_val)\n",
        "\n",
        "# print classification report for validation\n",
        "print(classification_report(y_val, predictions, target_names=['Not Fraud','Fraud']))\n",
        "# print(classification_report(y_val,target_names=['Not Fraud', 'Fraud']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4VdtsHvAbHW",
        "outputId": "bf0dacf0-7ce7-4e7f-e983-f1c5bb4a9418"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     22771\n",
            "       Fraud       0.73      0.53      0.61        36\n",
            "\n",
            "    accuracy                           1.00     22807\n",
            "   macro avg       0.87      0.76      0.81     22807\n",
            "weighted avg       1.00      1.00      1.00     22807\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction using test data. (unbalanced dataset)"
      ],
      "metadata": {
        "id": "1_F9pcqt67aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report for test data\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train.ravel())\n",
        "\n",
        "predictions = lr.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test, predictions, target_names=['Not Fraud','Fraud']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4W7NJ7LCaQD",
        "outputId": "beddeb5c-b8fd-4dc8-da0d-73fd6aa37648"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     21955\n",
            "       Fraud       0.91      0.64      0.75        45\n",
            "\n",
            "    accuracy                           1.00     22000\n",
            "   macro avg       0.95      0.82      0.88     22000\n",
            "weighted avg       1.00      1.00      1.00     22000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, lr.predict(x_test))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix for LR before class-balancing:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6SQUiE0i0sY",
        "outputId": "6761fb61-aac8-46e1-9254-30f51a6528d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for LR before class-balancing:\n",
            "[[21952     3]\n",
            " [   16    29]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "shallow_nn = Sequential()\n",
        "shallow_nn.add(InputLayer((x_train.shape[1],)))\n",
        "shallow_nn.add(Dense(2, 'relu'))\n",
        "shallow_nn.add(BatchNormalization())\n",
        "shallow_nn.add(Dense(1, 'sigmoid'))\n",
        "\n",
        "checkpoint = ModelCheckpoint('shallow_nn', save_best_only=True)\n",
        "shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8vhiNUORko0m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shallow_nn.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, callbacks=checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZR8v3sAkwG2",
        "outputId": "2cf2cb0a-b670-4ef8-a9ca-92bb6fbb2b45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "7500/7500 [==============================] - 32s 4ms/step - loss: 0.0469 - accuracy: 0.9909 - val_loss: 0.0073 - val_accuracy: 0.9993\n",
            "Epoch 2/5\n",
            "7500/7500 [==============================] - 23s 3ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0080 - val_accuracy: 0.9992\n",
            "Epoch 3/5\n",
            "7500/7500 [==============================] - 25s 3ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0094 - val_accuracy: 0.9992\n",
            "Epoch 4/5\n",
            "7500/7500 [==============================] - 35s 5ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0095 - val_accuracy: 0.9991\n",
            "Epoch 5/5\n",
            "7500/7500 [==============================] - 28s 4ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0086 - val_accuracy: 0.9990\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79df7c1a6f50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_net_predictions(model, x):\n",
        "  return (model.predict(x).flatten() > 0.5).astype(int)\n",
        "neural_net_predictions(shallow_nn, x_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt9KGpv2ldWO",
        "outputId": "998620bb-e308-47bd-e1a2-733a2062f2c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "713/713 [==============================] - 3s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_confusion_matrix(model, x, y_true, target_names=['Not Fraud', 'Fraud']):\n",
        "    # Get predictions from the model\n",
        "    y_pred = neural_net_predictions(model, x)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "    #classification report\n",
        "    from sklearn.metrics import classification_report\n",
        "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "# Print confusion matrix for validation data\n",
        "print_confusion_matrix(shallow_nn, x_val, y_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln0FZElokz2O",
        "outputId": "83589d5c-02aa-48a6-f2c9-e84129fd311e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "713/713 [==============================] - 2s 3ms/step\n",
            "Confusion Matrix:\n",
            "[[22758    13]\n",
            " [    9    27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     22771\n",
            "       Fraud       0.68      0.75      0.71        36\n",
            "\n",
            "    accuracy                           1.00     22807\n",
            "   macro avg       0.84      0.87      0.86     22807\n",
            "weighted avg       1.00      1.00      1.00     22807\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_confusion_matrix(model, x, y_true, target_names=['Not Fraud', 'Fraud']):\n",
        "    # Get predictions from the model\n",
        "    y_pred = neural_net_predictions(model, x)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "print_confusion_matrix(shallow_nn, x_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5GewjXGmmtG",
        "outputId": "059e330d-37fe-4a76-9b11-b2ec2815a23f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "713/713 [==============================] - 3s 4ms/step\n",
            "Confusion Matrix:\n",
            "[[22758    13]\n",
            " [    9    27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "# import SMOTE module from imblearn library\n",
        "# pip install imblearn (if you don't have imblearn in your system)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJdJQpQZDZkT",
        "outputId": "0651f0bc-acc1-4b9a-bd52-9b9f79d272b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before OverSampling, counts of label '1': 411\n",
            "Before OverSampling, counts of label '0': 239589 \n",
            "\n",
            "After OverSampling, the shape of train_X: (479178, 30)\n",
            "After OverSampling, the shape of train_y: (479178,) \n",
            "\n",
            "After OverSampling, counts of label '1': 239589\n",
            "After OverSampling, counts of label '0': 239589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the labels and counts before oversampling\n",
        "labels_before = ['Class 0', 'Class 1']\n",
        "counts_before = [sum(y_train == 0), sum(y_train == 1)]\n",
        "\n",
        "# Define the labels and counts after oversampling\n",
        "labels_after = ['Class 0 (Resampled)', 'Class 1 (Resampled)']\n",
        "counts_after = [sum(y_train_res == 0), sum(y_train_res == 1)]\n",
        "\n",
        "# Create subplots for before and after oversampling with smaller figure size\n",
        "fig, axs = plt.subplots(1, 2, figsize=(8, 4))  # Adjust the figsize here\n",
        "\n",
        "# Plot before oversampling\n",
        "axs[0].bar(labels_before, counts_before, color=['blue', 'orange'])\n",
        "axs[0].set_title('Class Distribution Before Oversampling')\n",
        "axs[0].set_xlabel('Class')\n",
        "axs[0].set_ylabel('Count')\n",
        "\n",
        "# Plot after oversampling\n",
        "axs[1].bar(labels_after, counts_after, color=['blue', 'orange'])\n",
        "axs[1].set_title('Class Distribution After SMOTE Oversampling')\n",
        "axs[1].set_xlabel('Class')\n",
        "axs[1].set_ylabel('Count')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "CqV57pT-sRrZ",
        "outputId": "d438bc18-b889-4735-c1e5-def24108cba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning the model using balanced dataset."
      ],
      "metadata": {
        "id": "CsmqnxcnC1v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#classification after smote\n",
        "lr_smote = LogisticRegression()\n",
        "lr_smote.fit(X_train_res, y_train_res.ravel())\n",
        "predictions = lr_smote.predict(x_test)\n",
        "\n",
        "# print(classification_report(y_test, predictions))\n",
        "print(classification_report(y_test, predictions, target_names=['Not Fraud','Fraud']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIJPQOSaFFxw",
        "outputId": "219cb39c-4911-4daa-f94c-e4ad516ae154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      0.98      0.99     21955\n",
            "       Fraud       0.07      0.91      0.13        45\n",
            "\n",
            "    accuracy                           0.98     22000\n",
            "   macro avg       0.54      0.94      0.56     22000\n",
            "weighted avg       1.00      0.98      0.99     22000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix after smote\n",
        "cm = confusion_matrix(y_test, lr_smote.predict(x_test))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whh9ZOuiI_lR",
        "outputId": "0d266e0a-294c-4086-ab20-b19e2265e0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[21386   576]\n",
            " [    3    35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix before smote\n",
        "cm = confusion_matrix(y_test, lr.predict(x_test))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx0Pb2gIKra_",
        "outputId": "3d19aa0d-8f54-47aa-d605-2349fc1c7e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[21957     5]\n",
            " [    8    30]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "\n",
        "joblib.dump(lr_smote, 'lr_smote.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Dnoo6sN6bd",
        "outputId": "010b4e64-2d70-4fb5-cfcf-d96d2a2b5834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr_smote.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDrWCip5Pf2V",
        "outputId": "e4efb126-4806-47b4-d195-1532457849ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'model' is your trained model\n",
        "# Save the model to a specific path on your Google Drive\n",
        "joblib.dump(lr_smote, '/content/drive/MyDrive/CPSC-597/lr_smote.pkl')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvbBmJ00QIHC",
        "outputId": "1272c5ef-e98a-4216-8d28-c13795724bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/CPSC-597/lr_smote.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "shallow_nn = Sequential()\n",
        "shallow_nn.add(InputLayer((X_train_res.shape[1],)))\n",
        "shallow_nn.add(Dense(2, 'relu'))\n",
        "shallow_nn.add(BatchNormalization())\n",
        "shallow_nn.add(Dense(1, 'sigmoid'))\n",
        "\n",
        "checkpoint = ModelCheckpoint('shallow_nn', save_best_only=True)\n",
        "shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EpXDHjwNvRiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shallow_nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeoZf-rJy2Cr",
        "outputId": "685c73be-59f5-472d-dd02-d1f3982b15cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 2)                 62        \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 2)                 8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73 (292.00 Byte)\n",
            "Trainable params: 69 (276.00 Byte)\n",
            "Non-trainable params: 4 (16.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shallow_nn.fit(X_train_res, y_train_res, validation_data=(x_val, y_val), epochs=5, callbacks=checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCv701Ipy6mj",
        "outputId": "70194914-9617-408c-f327-f2fb94a4fba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "14975/14975 [==============================] - 31s 2ms/step - loss: 0.2040 - accuracy: 0.9267 - val_loss: 0.0991 - val_accuracy: 0.9815\n",
            "Epoch 2/5\n",
            "14975/14975 [==============================] - 35s 2ms/step - loss: 0.1541 - accuracy: 0.9410 - val_loss: 0.0905 - val_accuracy: 0.9825\n",
            "Epoch 3/5\n",
            "14975/14975 [==============================] - 31s 2ms/step - loss: 0.1540 - accuracy: 0.9414 - val_loss: 0.0931 - val_accuracy: 0.9818\n",
            "Epoch 4/5\n",
            "14975/14975 [==============================] - 32s 2ms/step - loss: 0.1539 - accuracy: 0.9416 - val_loss: 0.0951 - val_accuracy: 0.9816\n",
            "Epoch 5/5\n",
            "14975/14975 [==============================] - 33s 2ms/step - loss: 0.1530 - accuracy: 0.9417 - val_loss: 0.0927 - val_accuracy: 0.9818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78613b60aad0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (shallow_nn.predict(x_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, target_names=['Not Fraud', 'Fraud']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP-ndrY2zmXr",
        "outputId": "645b38ea-b671-44f8-8a77-e3c5f15358fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "688/688 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     21962\n",
            "       Fraud       0.77      0.87      0.81        38\n",
            "\n",
            "    accuracy                           1.00     22000\n",
            "   macro avg       0.88      0.93      0.91     22000\n",
            "weighted avg       1.00      1.00      1.00     22000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QhDfE3sU4a-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LJEna710KLT",
        "outputId": "5dc280f6-13a4-4393-c47c-2ef5f2da7a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[21952    10]\n",
            " [    5    33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untill this point, SMOTE is giving better accuracy in detecting fraud using linear regression(Fraud       0.06      0.92      0.11).\n",
        "Sequencial neural network has slightly better precision and f1-score, lowering the accuracy of fetecting fraud. But model is significantly good. (0.77      0.87      0.81)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "55mAE1733piZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing autoencoders\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the credit card transaction dataset\n",
        "ae_data = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# Separate features and labels\n",
        "ae_x = ae_data.drop(\"Class\", axis=1)\n",
        "ae_y = ae_data[\"Class\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(ae_x, ae_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(input_dim, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "# Train the autoencoder on normal transactions\n",
        "model.fit(X_train[y_train == 0], X_train[y_train == 0],\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_test, X_test))\n",
        "\n",
        "# Reconstruct the test data and calculate reconstruction error\n",
        "reconstructed = model.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - reconstructed, 2), axis=1)\n",
        "threshold = np.mean(mse) + 2 * np.std(mse)  # Set threshold as mean + 2*std deviation\n",
        "\n",
        "# Predict fraud based on reconstruction error\n",
        "y_pred = (mse > threshold).astype(int)\n",
        "\n",
        "# Evaluate performance\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xlDQbwu8tAY",
        "outputId": "f0ff7d7d-d364-4b0d-dbe7-87ee9724cc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1777/1777 [==============================] - 5s 2ms/step - loss: 0.6991 - val_loss: 0.6725\n",
            "Epoch 2/10\n",
            "1777/1777 [==============================] - 5s 3ms/step - loss: 0.6420 - val_loss: 0.6604\n",
            "Epoch 3/10\n",
            "1777/1777 [==============================] - 6s 3ms/step - loss: 0.6350 - val_loss: 0.6579\n",
            "Epoch 4/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6340 - val_loss: 0.6573\n",
            "Epoch 5/10\n",
            "1777/1777 [==============================] - 5s 3ms/step - loss: 0.6335 - val_loss: 0.6570\n",
            "Epoch 6/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6333 - val_loss: 0.6568\n",
            "Epoch 7/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6333 - val_loss: 0.6568\n",
            "Epoch 8/10\n",
            "1777/1777 [==============================] - 5s 3ms/step - loss: 0.6332 - val_loss: 0.6571\n",
            "Epoch 9/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6332 - val_loss: 0.6567\n",
            "Epoch 10/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6332 - val_loss: 0.6569\n",
            "1781/1781 [==============================] - 2s 1ms/step\n",
            "[[56419   445]\n",
            " [   39    59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56864\n",
            "           1       0.12      0.60      0.20        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.56      0.80      0.60     56962\n",
            "weighted avg       1.00      0.99      0.99     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing autoencoders\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the credit card transaction dataset\n",
        "# ae_data = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# Separate features and labels\n",
        "# ae_x = ae_data.drop(\"Class\", axis=1)\n",
        "# ae_y = ae_data[\"Class\"]\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(ae_x, ae_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train_res)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(input_dim, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "# Train the autoencoder on normal transactions\n",
        "model.fit(X_train[y_train_res == 0], X_train[y_train_res == 0],\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_test, X_test))\n",
        "\n",
        "# Reconstruct the test data and calculate reconstruction error\n",
        "reconstructed = model.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - reconstructed, 2), axis=1)\n",
        "threshold = np.mean(mse) + 2 * np.std(mse)  # Set threshold as mean + 2*std deviation\n",
        "\n",
        "# Predict fraud based on reconstruction error\n",
        "y_pred = (mse > threshold).astype(int)\n",
        "\n",
        "# Evaluate performance\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3RgM6p8_wYe",
        "outputId": "76c8172f-88f7-44d4-a1d2-8b564d01b348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1872/1872 [==============================] - 8s 4ms/step - loss: 0.3337 - val_loss: 1.2752\n",
            "Epoch 2/10\n",
            "1872/1872 [==============================] - 5s 3ms/step - loss: 0.3117 - val_loss: 1.2720\n",
            "Epoch 3/10\n",
            "1872/1872 [==============================] - 6s 3ms/step - loss: 0.3049 - val_loss: 1.2483\n",
            "Epoch 4/10\n",
            "1872/1872 [==============================] - 6s 3ms/step - loss: 0.3022 - val_loss: 1.2485\n",
            "Epoch 5/10\n",
            "1872/1872 [==============================] - 4s 2ms/step - loss: 0.3021 - val_loss: 1.2475\n",
            "Epoch 6/10\n",
            "1872/1872 [==============================] - 4s 2ms/step - loss: 0.3020 - val_loss: 1.2474\n",
            "Epoch 7/10\n",
            "1872/1872 [==============================] - 6s 3ms/step - loss: 0.3019 - val_loss: 1.2465\n",
            "Epoch 8/10\n",
            "1872/1872 [==============================] - 4s 2ms/step - loss: 0.3019 - val_loss: 1.2482\n",
            "Epoch 9/10\n",
            "1872/1872 [==============================] - 4s 2ms/step - loss: 0.3015 - val_loss: 1.2434\n",
            "Epoch 10/10\n",
            "1872/1872 [==============================] - 5s 3ms/step - loss: 0.3014 - val_loss: 1.2422\n",
            "1781/1781 [==============================] - 2s 1ms/step\n",
            "[[56688   176]\n",
            " [   93     5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.03      0.05      0.04        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.51      0.52      0.52     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    }
  ]
}